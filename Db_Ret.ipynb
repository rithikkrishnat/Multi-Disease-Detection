{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172264e2-7e62-4bfb-8770-bdbce3b7150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5220653e-b289-46f6-8ec1-9b1de1346769",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"D:\\Human Disease Diagnosis\\dataset\\Diabetes\\train_1.csv\" \n",
    "image_dir = r\"D:\\Human Disease Diagnosis\\dataset\\Diabetes\\train\"  \n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8e36c-3c80-4f5b-9bbe-28cfa313d0b2",
   "metadata": {},
   "source": [
    "##### def preprocess_data(df, image_dir):\n",
    "    df[\"image_path\"] = df[\"id_code\"].apply(lambda x: os.path.join(image_dir, x + \".png\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c891a2-d6d1-461e-baca-92052baa5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_data(df, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d59ae0cc-a4a9-4f62-843f-756f929c790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f84d89-a3dd-447f-9ed9-6848402fb210",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d14d5c5a-f337-467d-afbf-f5eab1af6c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 826 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ribhu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 1898 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    df,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"diagnosis\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"raw\",\n",
    "    subset=\"training\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22645364-df42-470a-b138-0c9815f36c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_dataframe(\n",
    "    df,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"diagnosis\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"raw\",\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f357fe3-1571-4591-8ab3-3f7332e215fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "out = Dense(5, activation=\"softmax\")(x)  # 5 classes (0 to 4)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54fb5988-5979-4469-9bde-a507b804bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7e2794-b6be-423c-9231-80bdd6f598ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ribhu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4342 - loss: 1.4367   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ribhu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 6s/step - accuracy: 0.4343 - loss: 1.4356 - val_accuracy: 0.4660 - val_loss: 1.3006\n",
      "Epoch 2/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 5s/step - accuracy: 0.4992 - loss: 1.3208 - val_accuracy: 0.4660 - val_loss: 1.3070\n",
      "Epoch 3/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 5s/step - accuracy: 0.4841 - loss: 1.3124 - val_accuracy: 0.4660 - val_loss: 1.2818\n",
      "Epoch 4/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 5s/step - accuracy: 0.4860 - loss: 1.3212 - val_accuracy: 0.4660 - val_loss: 1.2950\n",
      "Epoch 5/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 5s/step - accuracy: 0.4485 - loss: 1.3727 - val_accuracy: 0.4660 - val_loss: 1.3116\n",
      "Epoch 6/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 5s/step - accuracy: 0.4930 - loss: 1.3373 - val_accuracy: 0.4660 - val_loss: 1.2935\n",
      "Epoch 7/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 5s/step - accuracy: 0.4835 - loss: 1.3594 - val_accuracy: 0.4660 - val_loss: 1.2802\n",
      "Epoch 8/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 5s/step - accuracy: 0.4608 - loss: 1.3664 - val_accuracy: 0.4660 - val_loss: 1.2893\n",
      "Epoch 9/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 5s/step - accuracy: 0.4747 - loss: 1.3738 - val_accuracy: 0.4660 - val_loss: 1.2832\n",
      "Epoch 10/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 5s/step - accuracy: 0.4826 - loss: 1.3359 - val_accuracy: 0.4660 - val_loss: 1.2865\n",
      "Epoch 11/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 5s/step - accuracy: 0.4788 - loss: 1.3564 - val_accuracy: 0.4660 - val_loss: 1.2855\n",
      "Epoch 12/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 5s/step - accuracy: 0.4565 - loss: 1.3555 - val_accuracy: 0.4660 - val_loss: 1.2872\n",
      "Epoch 13/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 5s/step - accuracy: 0.4680 - loss: 1.3758 - val_accuracy: 0.4660 - val_loss: 1.2877\n",
      "Epoch 14/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 5s/step - accuracy: 0.4799 - loss: 1.3600 - val_accuracy: 0.4660 - val_loss: 1.2935\n",
      "Epoch 15/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 5s/step - accuracy: 0.4598 - loss: 1.3816 - val_accuracy: 0.4660 - val_loss: 1.2921\n",
      "Epoch 16/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 5s/step - accuracy: 0.4590 - loss: 1.3392 - val_accuracy: 0.4660 - val_loss: 1.2854\n",
      "Epoch 17/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 5s/step - accuracy: 0.4594 - loss: 1.3657 - val_accuracy: 0.4660 - val_loss: 1.2901\n",
      "Epoch 18/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 5s/step - accuracy: 0.4904 - loss: 1.3249 - val_accuracy: 0.4660 - val_loss: 1.2938\n",
      "Epoch 19/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 5s/step - accuracy: 0.4595 - loss: 1.3449 - val_accuracy: 0.4660 - val_loss: 1.2886\n",
      "Epoch 20/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 5s/step - accuracy: 0.4865 - loss: 1.3508 - val_accuracy: 0.4660 - val_loss: 1.2941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1484f507cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "448b782c-8804-4636-b1c5-84197e949210",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"diabetic_retinopathy_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19281a1-6a45-49dc-a804-9be8a2062f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
